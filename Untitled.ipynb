{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.read_csv(\"yelp_academic_dataset_review_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116474it [12:58, 149.65it/s]\n"
     ]
    }
   ],
   "source": [
    "tags = set([\"JJ\", \"JJR\", \"JJS\", \"NN\", \"NNP\", \"NNS\", \"NNPS\"])\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "all_words = []\n",
    "for index, item in tqdm(s.iterrows()):\n",
    "    words = nltk.pos_tag(nltk.word_tokenize(item[\"text\"]))\n",
    "    words = [(regex.sub('', w).lower(), t) for w, t in words]\n",
    "    words = [w for w,t in words if t in tags ]\n",
    "    all_words += words\n",
    "set_all_words = set(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116474it [07:57, 243.88it/s]\n"
     ]
    }
   ],
   "source": [
    "common_words = [w for w, f in Counter(all_words).most_common(num_words)]\n",
    "words_dic = dict(zip(common_words, range(num_words)))\n",
    "vecs = []\n",
    "for index, item in tqdm(s.iterrows()):\n",
    "    words = nltk.word_tokenize(item[\"text\"])\n",
    "    vec = np.zeros(num_words)\n",
    "    for w in words:\n",
    "        if w in common_words:\n",
    "            vec[words_dic[w]] += 1\n",
    "    vecs += [vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X,np.array(list(s[\"stars\"])).reshape(116474,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('nav.csv', X, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116474, 1501)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edible',\n",
       " 'puffs',\n",
       " 'meatball',\n",
       " 'needless',\n",
       " 'words',\n",
       " 'fruit',\n",
       " 'awhile',\n",
       " 'ask',\n",
       " 'weekends',\n",
       " 'strange',\n",
       " 'tongue',\n",
       " 'wood',\n",
       " 'and',\n",
       " 'b',\n",
       " 'ambience',\n",
       " 'calzone',\n",
       " 'watery',\n",
       " 'sizes',\n",
       " 'which',\n",
       " 'brew',\n",
       " 'kinds',\n",
       " 'cookie',\n",
       " 'fajita',\n",
       " 'buffalo',\n",
       " 'welcome',\n",
       " 'caesar',\n",
       " 'hype',\n",
       " 'craving',\n",
       " 'coworker',\n",
       " 'sub',\n",
       " 'get',\n",
       " 'central',\n",
       " 'tortas',\n",
       " 'start',\n",
       " 'ate',\n",
       " 'ever',\n",
       " 'barbacoa',\n",
       " 'chimi',\n",
       " 'wok',\n",
       " 'olives',\n",
       " 'guests',\n",
       " 'fundido',\n",
       " 'anyway',\n",
       " 'glasses',\n",
       " 'reservation',\n",
       " 'major',\n",
       " 'gourmet',\n",
       " 'cards',\n",
       " 'sangria',\n",
       " 'phenomenal',\n",
       " 'air',\n",
       " 'smooth',\n",
       " 'ta',\n",
       " 'this',\n",
       " 'palace',\n",
       " 'pictures',\n",
       " 'shame',\n",
       " 'etc',\n",
       " 'burger',\n",
       " 'trash',\n",
       " 'serious',\n",
       " 'waiters',\n",
       " 'ten',\n",
       " 'french',\n",
       " 'do',\n",
       " 'america',\n",
       " 'nearby',\n",
       " 'joke',\n",
       " 'biggest',\n",
       " 'dad',\n",
       " 'concept',\n",
       " 'round',\n",
       " 'yelpers',\n",
       " 'del',\n",
       " 'ordered',\n",
       " 'refill',\n",
       " 'st',\n",
       " 'groupon',\n",
       " 'entrance',\n",
       " 'mex',\n",
       " 'carrots',\n",
       " 'courteous',\n",
       " 'bitter',\n",
       " 'knots',\n",
       " 'roast',\n",
       " 'ass',\n",
       " 'various',\n",
       " 'brick',\n",
       " 'system',\n",
       " 'dozen',\n",
       " 'excited',\n",
       " 'hurry',\n",
       " 'henderson',\n",
       " 'help',\n",
       " 'standards',\n",
       " 'needs',\n",
       " 'impressive',\n",
       " 'picture',\n",
       " 'signs',\n",
       " 'broth']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
